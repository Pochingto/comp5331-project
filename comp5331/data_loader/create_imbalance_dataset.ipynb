{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_imbalance_dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja4Zz_dSLV6v"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ImbalanceDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset, train_weights, test_weights):\n",
        "        self.train_weights = train_weights\n",
        "        self.test_weights = test_weights\n",
        "        self.train = dataset.train\n",
        "        #select train_index\n",
        "        train_index = []\n",
        "        for i, w in enumerate(self.train_weights):\n",
        "          index = np.where(dataset.train_labels == i)[0]\n",
        "          np.random.shuffle(index)\n",
        "          train_index = np.concatenate((train_index, index[:w]))\n",
        "        self.train_data = dataset.train_data[train_index]\n",
        "        self.train_labels = dataset.train_labels[train_index]\n",
        "\n",
        "\n",
        "        #select test_index\n",
        "        test_index = []\n",
        "        for i, w in enumerate(self.test_weights):\n",
        "          index = np.where(dataset.test_labels == i)[0]\n",
        "          np.random.shuffle(index)\n",
        "          test_index = np.concatenate((test_index, index[:w]))\n",
        "        self.test_data = dataset.test_data[test_index]\n",
        "        self.test_labels = dataset.test_labels[test_index]\n",
        "\n",
        "        self.len = len(self.train_labels)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.train_data[index], self.train_labels[index]) if self.train else (self.test_data[index], self.test_labels[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_labels) if self.train else len(self.test_labels)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRreB_qpBn-b"
      },
      "source": [
        "def get_dataset(name):\n",
        "  if name == \"minst\":\n",
        "    train_weights=np.asarray([4000,2000,1000,750,500,350,200,100,60,40])\n",
        "    test_weights = np.asarray([980,1135,1032,1010,982,892,958,1028,974,1009])\n",
        "    trainset = datasets.MNIST(\n",
        "          root='./MNIST/',\n",
        "          train=True,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "\n",
        "    testset = datasets.MNIST(\n",
        "          root='./MNIST/',\n",
        "          train=False,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "    trainset = ImbalanceDataset(trainset, train_weights, test_weights)\n",
        "    testset = ImbalanceDataset(testset, train_weights, test_weights)\n",
        "  elif name == \"fminst\":\n",
        "    train_weights=np.asarray([4000,2000,1000,750,500,350,200,100,60,40])\n",
        "    test_weights = np.asarray([1000,1000,1000,1000,1000,1000,1000,1000,1000,1000])\n",
        "    trainset = datasets.FashionMNIST(\n",
        "          root='./FMNIST/',\n",
        "          train=True,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "\n",
        "    testset = datasets.FashionMNIST(\n",
        "          root='./FMNIST/',\n",
        "          train=False,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )    \n",
        "    trainset = ImbalanceDataset(trainset, train_weights, test_weights)\n",
        "    testset = ImbalanceDataset(testset, train_weights, test_weights)\n",
        "  elif name == \"cifar\":\n",
        "    trainset = datasets.CIFAR10(\n",
        "          root='./CIFAR10/',\n",
        "          train=True,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "\n",
        "    testset = datasets.CIFAR10(\n",
        "          root='./CIFAR10/',\n",
        "          train=False,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "  elif name == \"svhn\":\n",
        "    trainset = datasets.SVHN(\n",
        "          root='./SVHN/',\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "\n",
        "    testset = datasets.SVHN(\n",
        "          root='./SVHN/',\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )    \n",
        "  elif name == \"celebA\":\n",
        "    trainset = datasets.CelebA(\n",
        "          root='./CelebA/',\n",
        "          train=True,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )\n",
        "\n",
        "    testset = datasets.CelebA(\n",
        "          root='./CelebA/',\n",
        "          train=False,\n",
        "          transform=transforms.ToTensor(),\n",
        "          download=True\n",
        "    )   \n",
        "  return trainset, testset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebHC-YdMDBxv",
        "outputId": "48fb725a-4b85-4018-d3bc-6a65cffc3a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainset, testset = get_dataset(\"minst\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E5GJrSIDIOo"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=200,shuffle=True, num_workers = 2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=200,shuffle=True, num_workers = 2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgSNpqnkBcwW",
        "outputId": "348501ab-ab44-4229-d18c-2c1fbea9a75a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "L = []\n",
        "for datas, labels in train_loader:\n",
        "    L = L+ labels.tolist()\n",
        "print(len(L))\n",
        "\n",
        "for i in range(10):\n",
        "  print(sum([i==j for j in L  ]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9000\n",
            "4000\n",
            "2000\n",
            "1000\n",
            "750\n",
            "500\n",
            "350\n",
            "200\n",
            "100\n",
            "60\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhCXEX0BeQ2",
        "outputId": "47115ad0-7c1c-46f9-f841-cef6122932c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "L = []\n",
        "for datas, labels in test_loader:\n",
        "    L = L+ labels.tolist()\n",
        "print(len(L))\n",
        "\n",
        "for i in range(10):\n",
        "  print(sum([i==j for j in L  ]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "980\n",
            "1135\n",
            "1032\n",
            "1010\n",
            "982\n",
            "892\n",
            "958\n",
            "1028\n",
            "974\n",
            "1009\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}